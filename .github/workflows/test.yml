name: Java CI

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - devel
    paths-ignore:
      - '.github/**'
      - 'bin/**'
      - 'demo/**'
      - 'docker/**'
      - 'lib/**'
      - 'python-integration-tests/**'
      - 'ChangeLog.md'
      - 'dev-README.md'
      - 'README.md'
  pull_request:
    types: [ opened, synchronize, reopened ]
    branches:
      - main
      - devel

jobs:


  test-python:
    timeout-minutes: 10
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: [3.9]
        scala-version: [2.12]
        spark:
          - spark-version: 3.2
            pyspark-version: 3.2.4
          - spark-version: 3.3
            pyspark-version: 3.3.3
          - spark-version: 3.4
            pyspark-version: 3.4.0
        topology: [single, cluster]
        java-version: [8, 11]
        docker-img: ["docker.io/arangodb/arangodb:3.12"]
        exclude:
          - topology: cluster
            java-version: 8
          - topology: single
            java-version: 11

    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-java@v2
        with:
          java-version: ${{matrix.java-version}}
          distribution: 'adopt'
          cache: maven
      - uses: actions/setup-python@v4
        with:
          python-version: ${{matrix.python-version}}
      - name: Start Database
        run: ./docker/start_db.sh
        env:
          STARTER_MODE: ${{matrix.topology}}
          DOCKER_IMAGE: ${{matrix.docker-img}}
      - name: Maven Info
        run: mvn -version
      - name: Install python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyspark==${{matrix.spark.pyspark-version}}
          pip install -r python-integration-tests/test-requirements.txt
      - name: Build Spark Datasource Artifact
        run: |
          mvn -e --no-transfer-progress -DskipTests -Pscala-${{matrix.scala-version}} -Pspark-${{matrix.spark.spark-version}} package
          find . -name "arangodb-spark-datasource-${{matrix.spark.spark-version}}_*-jar-with-dependencies.jar" -exec cp {} ./arangodb-spark-datasource-under-test.jar \;
      - name: Run tests for PySpark ${{matrix.spark.spark-version}} on Python ${{matrix.python-version}}
        run: |
          pytest python-integration-tests/integration --adb-datasource-jar ./arangodb-spark-datasource-under-test.jar --adb-hostname 172.28.0.1



## FIXME: sonar plugin requires Java 17
#  sonar:
#    timeout-minutes: 10
#    runs-on: ubuntu-latest
#
#    strategy:
#      fail-fast: false
#      matrix:
#        scala-version:
#          - 2.12
#        spark-version:
#          - 3.4
#        topology:
#          - single
#        java-version:
#          - 11
#        docker-img:
#          - docker.io/arangodb/arangodb:3.12
#
#    steps:
#      - uses: actions/checkout@v2
#        with:
#          fetch-depth: 0
#      - uses: actions/setup-java@v2
#        with:
#          java-version: ${{matrix.java-version}}
#          distribution: 'adopt'
#          cache: maven
#      - name: Start Database
#        run: ./docker/start_db.sh
#        env:
#          STARTER_MODE: ${{matrix.topology}}
#          DOCKER_IMAGE: ${{matrix.docker-img}}
#      - name: Cache SonarCloud packages
#        uses: actions/cache@v2
#        with:
#          path: ~/.sonar/cache
#          key: ${{ runner.os }}-sonar
#          restore-keys: ${{ runner.os }}-sonar
#      - name: Info
#        run: mvn -version
#      - name: Build and analyze
#        env:
#          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Needed to get PR information, if any
#          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
#        run: mvn -e --no-transfer-progress -Pscala-${{matrix.scala-version}} -Pspark-${{matrix.spark-version}} -Dgpg.skip=true -B verify org.sonarsource.scanner.maven:sonar-maven-plugin:sonar -Dsonar.projectKey=arangodb_arangodb-spark-datasource
